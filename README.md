# mathkernel


Generate math kernels for non-linear optimization and dynamics.


## Usage

```
sbcl
(ql:quickload :cando-kernels)
(energy-kernels:write-all "/tmp/code/")
```
This builds molecular modeling kernels for evaluating stretch, angle, dihedral, nonbond and nonbond+distance-dependent-dielectric+cutoff terms
and writes optimized C code into /tmp/code/.

Ask ChatGPT what that means if you want to learn more.  It's math for building molecules.


## Documentation

[Documentation for defkernel (generated by ChatGPT)](docs/mathkernel.md)


## Notes 

### Update Dec 15, 2025.

Ok, I'm much LESS enamored by the coding abilities of ChatGPT5.1-codex-max.
ChatGPT wrote a compiler for mathematical expressions that handles single blocks of statements
very well. Everything looked good until I started working seriously with the nonbond_dd_cutoff kernel
which generates a branching tree of equations that need separate gradient and hessian analytical terms.
Branching requires a completely different approach to the compiler.  You need environments and a tree walker
that updates the environment as it walks statements.  ChatGPT was not good at this.  It doesn't reason well
with recursive algorithms and algorithms where information and control is more distributed across complex
connected data structures and methods of generic functions.

I spent a lot of time debugging broken code and it can generate broken code really fast.
I wouldn't use it again to write a compiler.  I would put it in read only mode and ask it to check
my code and suggest changes and then I would carefully integrate suggestions line by line.

### Original post Dec 1, 2025.

This application was vibe-coded using ChatGPT5.1 by Christian Schafmeister over five days starting on Nov 23 2025.
I implemented an application like this 25 years ago in Mathematica and it drives me crazy everytime I have to get it
working again to make changes. We implemented Cando (https://github.com/cando-developers/cando.git) and 
Clasp (https://github.com/clasp-developers/clasp.git). Cando is a Common Lisp implementation to write complex molecular
modelling code. Why?  Because if you are going to write software to build molecules you should write it in the language
of the universe (lisp).  Also - Python sucks.

I started with a $20/month OpenAI account and things started very nicely but after a day I noticed
that ChatGPT was running out of steam and starting to ping-pong between approaches and forgetting that
I had given up on approaches.  So I upgraded my account to the $200/month and pasted all the code
I had up to that point into a project and started from there.  It was impressively "smarter", it suggested ideas
that had more depth and it seemed to have a much better grasp of the problem.
Over the next four days I asked for features one at a time and ChatGPT kept giving me code that I would test.
I asked it for regression tests and kept adding them and testing functions and finding and fixing bugs.
There were no serious bugs and the project seemed to improve smoothly.  I learned a lot about automatic
differentiation, rule rewriting and optimization passes.

After five days - 10,846 lines of code (simple wc count)

Thoughts:
0. Most of this was vibe-coded using gpt-5.1 at the reasoning level "high".  When I set the reasoning lower then things go off the rails and I start getting bad code.
1. I didn't trust ChatGPT to calculate symbolic derivatives properly or to generate
   code to calculate symbolic derivatives.  So I spent two days vibe-coding the facility
   to compare them to each other.  You will notice some of the kernels have hardcoded partial
   derivatives. If you supply them and ask for automatic differentiation it will compare them
   to each other.  They matched from the start!
2. I'm amazed... and so excited by how powerful this is.
3. ChatGPT generated bugs - no question. I spent about half the time finding and fixing them with
   ChatGPT help.
4. ChatGPT has a problem with closing parentheses for very long functions.  I found that it helped
   to ask it to write the code as an abstract syntax tree and then convert that to code.  It also likes to
   use 't' as a variable (a Common Lisp no no).  I told it to stop doing that.
